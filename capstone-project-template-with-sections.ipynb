{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09225a2c-0cd6-4073-97d0-2dd2a3aa100e",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69edfd9c-adc0-4ab5-b7a2-828e8d0d79a8",
   "metadata": {},
   "source": [
    "## Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd43ec-abad-4256-8298-59d609304bb0",
   "metadata": {},
   "source": [
    "Joe Udacity  \n",
    "December 31st, 2050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a59c3-88c2-40c0-998a-377dd39d6e37",
   "metadata": {},
   "source": [
    "## I. Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a169148-1884-4a79-a4f3-69099ff0ca5a",
   "metadata": {},
   "source": [
    "_(approx. 1-2 pages)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931343f0-60fb-435b-aafe-f3f6a36cf232",
   "metadata": {},
   "source": [
    "### Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79ef2d-64ec-40f0-b378-8533d51ae49e",
   "metadata": {},
   "source": [
    "In this section, look to provide a high-level overview of the project in layman’s terms. Questions to ask yourself when writing this section:\n",
    "- _Has an overview of the project been provided, such as the problem domain, project origin, and related datasets or input data?_\n",
    "- _Has enough background information been given so that an uninformed reader would understand the problem domain and following problem statement?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d07e44-72d3-423c-90e1-4334b658530f",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a57890-e8a7-4543-b484-43ebe192f7f1",
   "metadata": {},
   "source": [
    "In this section, you will want to clearly define the problem that you are trying to solve, including the strategy (outline of tasks) you will use to achieve the desired solution. You should also thoroughly discuss what the intended solution will be for this problem. Questions to ask yourself when writing this section:\n",
    "- _Is the problem statement clearly defined? Will the reader understand what you are expecting to solve?_\n",
    "- _Have you thoroughly discussed how you will attempt to solve the problem?_\n",
    "- _Is an anticipated solution clearly defined? Will the reader understand what results you are looking for?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9208a4-e972-4305-b289-9d16b661919e",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1ee74-b45d-408c-9b1c-e43799501ba8",
   "metadata": {},
   "source": [
    "In this section, you will need to clearly define the metrics or calculations you will use to measure performance of a model or result in your project. These calculations and metrics should be justified based on the characteristics of the problem and problem domain. Questions to ask yourself when writing this section:\n",
    "- _Are the metrics you’ve chosen to measure the performance of your models clearly discussed and defined?_\n",
    "- _Have you provided reasonable justification for the metrics chosen based on the problem and solution?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3492fa19-9680-49ec-978c-e9c1374cb11e",
   "metadata": {},
   "source": [
    "## II. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daa600-2a70-412d-af8f-9e48c24104d8",
   "metadata": {},
   "source": [
    "_(approx. 2-4 pages)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80e37f-2c61-4a5b-975e-0f98ff34d09b",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca1004-bb1c-4c25-aedf-30409d13adbc",
   "metadata": {},
   "source": [
    "In this section, you will be expected to analyze the data you are using for the problem. This data can either be in the form of a dataset (or datasets), input data (or input files), or even an environment. The type of data should be thoroughly described and, if possible, have basic statistics and information presented (such as discussion of input features or defining characteristics about the input or environment). Any abnormalities or interesting qualities about the data that may need to be addressed have been identified (such as features that need to be transformed or the possibility of outliers). Questions to ask yourself when writing this section:\n",
    "- _If a dataset is present for this problem, have you thoroughly discussed certain features about the dataset? Has a data sample been provided to the reader?_\n",
    "- _If a dataset is present for this problem, are statistics about the dataset calculated and reported? Have any relevant results from this calculation been discussed?_\n",
    "- _If a dataset is **not** present for this problem, has discussion been made about the input space or input data for your problem?_\n",
    "- _Are there any abnormalities or characteristics about the input space or dataset that need to be addressed? (categorical variables, missing values, outliers, etc.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9f898c-c99b-4d13-b71f-2ba3584839be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting category-encoders\n",
      "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from category-encoders) (0.13.5)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from category-encoders) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from category-encoders) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from category-encoders) (1.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from category-encoders) (1.8.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from category-encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas>=1.0.5->category-encoders) (2022.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category-encoders) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category-encoders) (1.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from statsmodels>=0.9.0->category-encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category-encoders) (3.0.9)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6e4ba18-6b92-400b-86ae-439cb3bac9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#General dependencies\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "#Data preprocessing\n",
    "from io import StringIO\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "#Model training and hyperparameter tuning\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig, ProfilerRule, rule_configs, ProfilerConfig, FrameworkProfile\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "from sagemaker.pytorch import PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08961008-6869-460c-823b-043377e98d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prepare commonly used objects\n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c218189-ae35-41e1-ad04-8945665f2be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = s3_client.get_object(Bucket=bucket, Key='data/data.csv')\n",
    "body=response['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cf5054-2d1e-48d0-86e7-57232f54a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16211/285887691.py:3: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(StringIO(data))\n"
     ]
    }
   ],
   "source": [
    "#Import dataset from s3\n",
    "data = body.read().decode('utf-8')\n",
    "df = pd.read_csv(StringIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e797d433-188e-45bb-b452-d58da25a83bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceased</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>arrival_transport</th>\n",
       "      <th>existing_doses</th>\n",
       "      <th>medicine_dispensations</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pain</th>\n",
       "      <th>acuity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14188788</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19659841</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11074777</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WALK IN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11075647</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WALK IN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>11858930</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>HELICOPTER</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deceased  subject_id  gender   race arrival_transport  existing_doses  \\\n",
       "0         0    14188788       1  OTHER         AMBULANCE               0   \n",
       "1         0    19659841       1  OTHER         AMBULANCE               1   \n",
       "2         0    11074777       1  WHITE           WALK IN               4   \n",
       "3         0    11075647       0  WHITE           WALK IN               1   \n",
       "4         0    11858930       1  WHITE        HELICOPTER               0   \n",
       "\n",
       "   medicine_dispensations  temperature  heartrate  resprate  o2sat  sbp  dbp  \\\n",
       "0                       6          NaN        NaN       NaN    NaN  NaN  NaN   \n",
       "1                      12          NaN        NaN       NaN    NaN  NaN  NaN   \n",
       "2                       0          NaN        NaN       NaN    NaN  NaN  NaN   \n",
       "3                       0          NaN        NaN       NaN    NaN  NaN  NaN   \n",
       "4                       6          NaN        NaN       NaN    NaN  NaN  NaN   \n",
       "\n",
       "  pain  acuity  \n",
       "0  NaN     NaN  \n",
       "1  NaN     NaN  \n",
       "2  NaN     NaN  \n",
       "3  NaN     NaN  \n",
       "4  NaN     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318fe79c-e97d-4e72-a32e-345aa9e67bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205504 entries, 0 to 205503\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   deceased                205504 non-null  int64  \n",
      " 1   subject_id              205504 non-null  int64  \n",
      " 2   gender                  205504 non-null  int64  \n",
      " 3   race                    205504 non-null  object \n",
      " 4   arrival_transport       205504 non-null  object \n",
      " 5   existing_doses          205504 non-null  int64  \n",
      " 6   medicine_dispensations  205504 non-null  int64  \n",
      " 7   temperature             191025 non-null  float64\n",
      " 8   heartrate               194174 non-null  float64\n",
      " 9   resprate                192573 non-null  float64\n",
      " 10  o2sat                   192534 non-null  float64\n",
      " 11  sbp                     193632 non-null  float64\n",
      " 12  dbp                     193241 non-null  float64\n",
      " 13  pain                    197462 non-null  object \n",
      " 14  acuity                  200428 non-null  float64\n",
      "dtypes: float64(7), int64(5), object(3)\n",
      "memory usage: 23.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee1edca-c230-4872-a4e8-299ff0c9d75f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceased\n",
      "Missing values: 0\n",
      "Percentage missing values:  0.00% \n",
      "\n",
      "subject_id\n",
      "Missing values: 0\n",
      "Percentage missing values:  0.00% \n",
      "\n",
      "gender\n",
      "Missing values: 0\n",
      "Percentage missing values:  0.00% \n",
      "\n",
      "race\n",
      "Missing values: 0\n",
      "Percentage missing values:  0.00% \n",
      "\n",
      "arrival_transport\n",
      "Missing values: 0\n",
      "Percentage missing values:  0.00% \n",
      "\n",
      "existing_doses\n",
      "Missing values: 0\n",
      "Percentage missing values:  0.00% \n",
      "\n",
      "medicine_dispensations\n",
      "Missing values: 0\n",
      "Percentage missing values:  0.00% \n",
      "\n",
      "temperature\n",
      "Missing values: 14479\n",
      "Percentage missing values:  7.05% \n",
      "\n",
      "heartrate\n",
      "Missing values: 11330\n",
      "Percentage missing values:  5.51% \n",
      "\n",
      "resprate\n",
      "Missing values: 12931\n",
      "Percentage missing values:  6.29% \n",
      "\n",
      "o2sat\n",
      "Missing values: 12970\n",
      "Percentage missing values:  6.31% \n",
      "\n",
      "sbp\n",
      "Missing values: 11872\n",
      "Percentage missing values:  5.78% \n",
      "\n",
      "dbp\n",
      "Missing values: 12263\n",
      "Percentage missing values:  5.97% \n",
      "\n",
      "pain\n",
      "Missing values: 8042\n",
      "Percentage missing values:  3.91% \n",
      "\n",
      "acuity\n",
      "Missing values: 5076\n",
      "Percentage missing values:  2.47% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column)\n",
    "    missing_values = df[column].isna().sum()\n",
    "    print(f'Missing values: {missing_values}')\n",
    "    print(f'Percentage missing values: {missing_values / len(df[column]) : .2%}', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c08386a-a91d-42d9-b5c4-ed505c1f4123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    186330\n",
      "1     19174\n",
      "Name: deceased, dtype: int64\n",
      "14188788    1\n",
      "12272035    1\n",
      "15947312    1\n",
      "15327112    1\n",
      "11648349    1\n",
      "           ..\n",
      "16094974    1\n",
      "16106036    1\n",
      "16355756    1\n",
      "16476300    1\n",
      "13716295    1\n",
      "Name: subject_id, Length: 205504, dtype: int64\n",
      "0    109545\n",
      "1     95959\n",
      "Name: gender, dtype: int64\n",
      "WHITE                                        118962\n",
      "BLACK/AFRICAN AMERICAN                        25677\n",
      "OTHER                                         11875\n",
      "UNKNOWN                                        6409\n",
      "ASIAN                                          4955\n",
      "HISPANIC/LATINO - PUERTO RICAN                 4623\n",
      "WHITE - OTHER EUROPEAN                         4512\n",
      "ASIAN - CHINESE                                4159\n",
      "HISPANIC/LATINO - DOMINICAN                    3225\n",
      "BLACK/CAPE VERDEAN                             2789\n",
      "BLACK/AFRICAN                                  2405\n",
      "WHITE - RUSSIAN                                2213\n",
      "BLACK/CARIBBEAN ISLAND                         1667\n",
      "HISPANIC OR LATINO                             1328\n",
      "HISPANIC/LATINO - GUATEMALAN                   1070\n",
      "ASIAN - ASIAN INDIAN                            903\n",
      "ASIAN - SOUTH EAST ASIAN                        861\n",
      "WHITE - BRAZILIAN                               854\n",
      "HISPANIC/LATINO - MEXICAN                       694\n",
      "HISPANIC/LATINO - SALVADORAN                    682\n",
      "WHITE - EASTERN EUROPEAN                        664\n",
      "HISPANIC/LATINO - COLUMBIAN                     646\n",
      "PORTUGUESE                                      631\n",
      "AMERICAN INDIAN/ALASKA NATIVE                   528\n",
      "SOUTH AMERICAN                                  523\n",
      "ASIAN - KOREAN                                  522\n",
      "PATIENT DECLINED TO ANSWER                      451\n",
      "HISPANIC/LATINO - HONDURAN                      384\n",
      "HISPANIC/LATINO - CENTRAL AMERICAN              330\n",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER       309\n",
      "HISPANIC/LATINO - CUBAN                         284\n",
      "UNABLE TO OBTAIN                                210\n",
      "MULTIPLE RACE/ETHNICITY                         159\n",
      "Name: race, dtype: int64\n",
      "WALK IN       119599\n",
      "AMBULANCE      75745\n",
      "UNKNOWN         8741\n",
      "HELICOPTER       719\n",
      "OTHER            700\n",
      "Name: arrival_transport, dtype: int64\n",
      "0       64040\n",
      "1       18901\n",
      "2       13337\n",
      "3       10452\n",
      "4        8559\n",
      "        ...  \n",
      "605         1\n",
      "811         1\n",
      "434         1\n",
      "1673        1\n",
      "1106        1\n",
      "Name: existing_doses, Length: 747, dtype: int64\n",
      "0      48736\n",
      "1      22317\n",
      "2      21637\n",
      "3      16105\n",
      "4      14483\n",
      "       ...  \n",
      "826        1\n",
      "420        1\n",
      "451        1\n",
      "402        1\n",
      "386        1\n",
      "Name: medicine_dispensations, Length: 391, dtype: int64\n",
      "98.00     14724\n",
      "97.80     12881\n",
      "98.20     11429\n",
      "98.40      9809\n",
      "97.60      9527\n",
      "          ...  \n",
      "105.10        1\n",
      "98.84         1\n",
      "93.80         1\n",
      "37.90         1\n",
      "86.40         1\n",
      "Name: temperature, Length: 368, dtype: int64\n",
      "80.0     8002\n",
      "88.0     6534\n",
      "72.0     5352\n",
      "90.0     5348\n",
      "78.0     5231\n",
      "         ... \n",
      "171.0       1\n",
      "188.0       1\n",
      "181.0       1\n",
      "14.0        1\n",
      "98.5        1\n",
      "Name: heartrate, Length: 196, dtype: int64\n",
      "18.0     75261\n",
      "16.0     69389\n",
      "20.0     18517\n",
      "14.0      8033\n",
      "17.0      5191\n",
      "         ...  \n",
      "47.0         1\n",
      "43.0         1\n",
      "67.0         1\n",
      "187.0        1\n",
      "100.0        1\n",
      "Name: resprate, Length: 66, dtype: int64\n",
      "100.0    84076\n",
      "99.0     31430\n",
      "98.0     30336\n",
      "97.0     19053\n",
      "96.0     12633\n",
      "         ...  \n",
      "109.0        1\n",
      "2.0          1\n",
      "62.0         1\n",
      "58.0         1\n",
      "98.4         1\n",
      "Name: o2sat, Length: 72, dtype: int64\n",
      "130.0     4483\n",
      "128.0     4115\n",
      "132.0     4062\n",
      "124.0     3947\n",
      "126.0     3892\n",
      "          ... \n",
      "259.0        1\n",
      "249.0        1\n",
      "258.0        1\n",
      "56.0         1\n",
      "9656.0       1\n",
      "Name: sbp, Length: 250, dtype: int64\n",
      "80.0      6532\n",
      "78.0      6119\n",
      "70.0      6017\n",
      "76.0      5964\n",
      "74.0      5693\n",
      "          ... \n",
      "785.0        1\n",
      "663.0        1\n",
      "953.0        1\n",
      "7102.0       1\n",
      "215.0        1\n",
      "Name: dbp, Length: 359, dtype: int64\n",
      "0                                                      57501\n",
      "8                                                      18228\n",
      "5                                                      15339\n",
      "10                                                     15307\n",
      "7                                                      15193\n",
      "                                                       ...  \n",
      "u/'a                                                       1\n",
      "numb                                                       1\n",
      "nonw                                                       1\n",
      "lots                                                       1\n",
      "unable to give a number, says it's hard to describe        1\n",
      "Name: pain, Length: 566, dtype: int64\n",
      "3.0    105658\n",
      "2.0     66298\n",
      "4.0     15466\n",
      "1.0     12483\n",
      "5.0       523\n",
      "Name: acuity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be4a6b2-1266-46e5-b4b0-b8adca21f1df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan '&' ')' '+' '-' '.' '0' 0 1 2 3 4 5 6 '6' '7' '8' '9' '?' 'C' 'T' 'U'\n",
      " 'c' 'i' 'o' 's' 't' 'u' ' 0' ' 4' ' 6' ' c' '++' '-0' '.0' '.3' '.5' '/?'\n",
      " '0 ' '0-' '0.' '0/' '00' '01' '03' '06' '07' '08' '09' '10' '11' '12'\n",
      " '13' '14' '15' '16' '18' '19' '2,' '2.' '20' '23' '3 ' '3t' '5 ' '51'\n",
      " '54' '56' '6 ' '61' '68' '6`' '7/' '70' '73' '75' '8 ' '8,' '8.' '8/'\n",
      " '88' '9 ' '9+' '90' '95' '97' '98' '<1' '?/' '??' 'CP' 'RA' 'UA' 'Ua'\n",
      " 'na' 'no' 'o3' 'ok' 'ph' 'ra' 'uA' 'ua' 'un' 'ut' ' 10' '0  ' '0, ' '0-1'\n",
      " '0-2' '0-5' '0-7' '0-8' '0-9' '0..' '0.5' '069' '1 0' '1-2' '1-3' '1-7'\n",
      " '1.2' '1.5' '1/2' '10 ' '10+' '10.' '10/' '100' '134' '180' '1`0' '2-3'\n",
      " '2-4' '2-6' '2-7' '2-8' '2-9' '2. ' '2.5' '3  ' '3-4' '3-5' '3-6' '3-7'\n",
      " '3.5' '4-5' '4-8' '4. ' '4.5' '4/9' '5-6' '5-8' '5-9' '5.5' '5.8' '5/7'\n",
      " '5/8' '5/9' '6-7' '6-8' '6-9' '6.5' '7-6' '7-8' '7-9' '7.5' '7/8' '8  '\n",
      " '8-9' '8.5' '8.6' '8.7' '8/6' '8/9' '9  ' '9-8' '9.4' '9.5' '9.7' '9.9'\n",
      " '9/6' '>10' 'AMS' 'Bad' 'ETT' 'INT' 'NAD' 'Pt ' 'Ref' 'U.A' 'U/A' 'UTA'\n",
      " 'UTa' '___' '`10' 'bad' 'ett' 'low' 'mod' 'nha' 'pta' 'red' 'u/a' 'uTA'\n",
      " 'unk' 'uta' 'utd' 'uti' 'uto' 'uts' 'yes' '\"11\"' '\"12\"' '\"13\"' '\"15\"'\n",
      " '\"20\"' '\"60\"' '\"no\"' '0-10' '0pcn' '1/10' '10. ' '10/5' '2-10' '3, 7'\n",
      " '3-10' '3-11' '3/10' '4  H' '4-10' '5-10' '5/10' '6-10' '6/10' '7-10'\n",
      " '7.  ' '8,10' '8-10' '8.59' '8/10' '81/2' '9-10' '9/10' 'Mild' 'UTA '\n",
      " 'ache' 'achy' 'alot' 'cirt' 'crit' 'dull' 'fine' 'good' 'lots' 'mild'\n",
      " 'none' 'nonw' 'numb' 'pain' 'some' 'sore' \"u/'a\" 'u/a ' 'urta' 'uta '\n",
      " 'utts' 'vent' 'very' 'yes ' 'yes.' '  6-9' '\"10+\"' '\"110\"' '\"bad\"'\n",
      " '\"yes\"' '098.6' '10...' '10/10' '30-40' '5 1/2' '7-7.5' '7.235' '7.5-8'\n",
      " '8.5-9' '9 1.2' '98.60' 'a lot' 'achey' 'awful' 'balit' 'bipap' 'criot'\n",
      " 'crit ' 'criut' 'dont ' 'error' 'hurts' 'itchy' 'minor' 'mucho' 'pain '\n",
      " 'right' 'scary' 'sharp' 'sleep' 'small' 'so so' 'tight' 'u/a. ' 'uable'\n",
      " 'unabe' 'unale' 'unbel' 'unble' '\"1000\"' '\"Alot\"' '\"alot\"' '\"pain\"'\n",
      " '0-8/10' '0no nf' '8.5-10' '9.5-10' 'ASLEEP' 'UNABLE' 'Unable' 'asleep'\n",
      " 'better' 'cramps' 'crying' 'denies' 'inable' 'little' 'medium' 'middle'\n",
      " 'other ' 'pehosp' 'prehsp' 'severe' 'sleepy' 'slight' 'stings' 'strong'\n",
      " 'tender' 'throbs' 'trauma' 'twingy' 'uanble' 'uanlbe' 'unabke' 'unabl3'\n",
      " 'unable' 'unablw' 'unalbe' 'unale ' 'unbale' 'uncoop' 'unknwn' 'unqble'\n",
      " 'unresp' 'varies' '\"a lot\"' '\"heavy\"' 'FACES 4' 'L chest' 'REFUSED'\n",
      " 'Refused' 'Unable ' 'aphasic' 'asleep ' 'bloated' 'burning' 'critcal'\n",
      " 'denies ' 'diffuse' 'moaning' 'no pain' 'not bac' 'not bad' 'over 10'\n",
      " 'painful' 'poquito' 'prehosp' 'prehsop' 'reduced' 'refused' 'refuses'\n",
      " 'sedated' 'trauma ' 'trigger' 'un able' 'unabale' 'unabkle' 'unabl e'\n",
      " 'unable ' 'unable.' 'unablwe' 'unalb e' 'unclear' 'unjable' 'unknown'\n",
      " 'untabl ' '\"little\"' ':unable\"' 'CRITICAL' 'Critical' 'Moderate'\n",
      " 'Refusing' 'a little' 'all over' 'annoying' 'constant' 'cramping'\n",
      " 'critcal ' 'critial ' 'critica;' 'critical' 'crtiical' 'declined'\n",
      " 'gi upset' 'it hurts' 'leg pain' 'moaning ' 'moderate' 'not able'\n",
      " 'not much' 'pinching' 'pre hosp' 'pre-hosp' 'prehosp ' 'pressure'\n",
      " 'real bad' 'refused ' 'refusing' 'sleeping' 'somulent' 'tiny bit'\n",
      " 'too much' 'unaknown' 'unknow n' 'unknown ' 'variable' 'very bad'\n",
      " ' a little' '\"alittle\"' '\"painful\"' '\"so much\"' '\"tension\"' 'INTUBATED'\n",
      " 'Intubated' 'agitated ' 'bone pain' 'critical ' 'criticial' 'dull achy'\n",
      " 'grimacing' 'heartburn' 'heaviness' 'intubated' 'nonverbal' 'refusing '\n",
      " 'see below' 'stiffness' 'throbbing' 'tightness' 'tolerable' 'uncomfort'\n",
      " '\" alittle\"' '\"Too much\"' '\"a little\"' '\"moderate\"' '\"not much\"'\n",
      " '\"real bad\"' 'Non-verbal' 'controlled' 'critical; ' 'discomfort'\n",
      " 'everywhere' 'hurts alot' 'intubuated' 'less sharp' 'little bit'\n",
      " 'manageable' 'non verbal' 'not normal' 'not really' 'not to bad'\n",
      " 'pretty bad' 'unable 97/' 'when i pee' '\"litte bit\"' '\"up there\" '\n",
      " 'mild aches ' 'not too bad' 'pretty badf' 'wont answer' '\"discomfort\"'\n",
      " 'Unresponsive' 'chronic pain' 'excrutiating' \"i don't know\"\n",
      " 'intermittent' 'not that bad' 'not too bad.' 'pre-hospital'\n",
      " 'really hurts' 'very painful' '\"borderline\" ' '\"negligible\" '\n",
      " '\"pretty high\"' '\"slight pain\"' '10 w/ walking' 'achy all over'\n",
      " 'not much pain' 'too much pain' 'unable trauma' 'uncomfortable'\n",
      " '10 w/ movement' 'almost nothing' 'hurts to touch' 'it is up there'\n",
      " 'just bodyaches' 'quite p ainful' '\"a little bit.\"' '\"a little more\"'\n",
      " '0sent  for  lab' 'mild discomfort' 'slight pressure' 'total body pain'\n",
      " 'unable to score' '\"maybe a little\"' 'intense pressure'\n",
      " 'not comfortable.' 'not very painful' 'through the roof'\n",
      " 'uanble to answer' 'unable d/t intox' 'unable to access'\n",
      " 'unable to assess' 'unable to give #' 'unable to obtain'\n",
      " 'constant pressure' 'hurts when moving' 'no pain if seated'\n",
      " 'not strong at all' 'only a little bit' 'refused to answer'\n",
      " 'refuses to answer' 'unable - sleeping' '\"hurts everywhere\"'\n",
      " 'constant discomfort' 'FACES pain scale of 7' 'no pain if not moving'\n",
      " 'when i touch it hurts' 'CP 4/10 and groin 7/10' 'little bit of pressure'\n",
      " 'c/o severe HA since mon' 'did not give pain scale'\n",
      " 'refusing to give a number' '\"I dont do the pain scale\"'\n",
      " 'unable to report (aphasic)' '7 chronic back and neck pain'\n",
      " \"it doesn't hurt unless i move it\" '8/ paronychia lanced   3  days  ago'\n",
      " '\"not as bad not, they gave me tylenol\"'\n",
      " '10 (but dozing off during questioning)'\n",
      " 'Pt states he is unable to give me a number '\n",
      " \"unable to give a number, says it's hard to describe\"]\n"
     ]
    }
   ],
   "source": [
    "print(df['pain'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ecc6a-0fcf-425c-aeb1-f256ec918cd6",
   "metadata": {},
   "source": [
    "### Exploratory Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bf4cc-1f52-4575-9584-884bb164720d",
   "metadata": {},
   "source": [
    "In this section, you will need to provide some form of visualization that summarizes or extracts a relevant characteristic or feature about the data. The visualization should adequately support the data being used. Discuss why this visualization was chosen and how it is relevant. Questions to ask yourself when writing this section:\n",
    "- _Have you visualized a relevant characteristic or feature about the dataset or input data?_\n",
    "- _Is the visualization thoroughly analyzed and discussed?_\n",
    "- _If a plot is provided, are the axes, title, and datum clearly defined?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddfa0e4-31c4-4b2a-a48b-63d2dc480eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f7bad-24f4-47cb-8c12-3fdaf9e258c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7437ca13-32ff-48b4-ac25-cc25affa29c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['deceased'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047cedf-401c-4c71-ba59-7e20b59b9f78",
   "metadata": {},
   "source": [
    "### Algorithms and Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0dc699-7c70-460a-b207-e76495f51732",
   "metadata": {},
   "source": [
    "In this section, you will need to discuss the algorithms and techniques you intend to use for solving the problem. You should justify the use of each one based on the characteristics of the problem and the problem domain. Questions to ask yourself when writing this section:\n",
    "- _Are the algorithms you will use, including any default variables/parameters in the project clearly defined?_\n",
    "- _Are the techniques to be used thoroughly discussed and justified?_\n",
    "- _Is it made clear how the input data or datasets will be handled by the algorithms and techniques chosen?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137b9c1-84a4-4b81-8b71-6b3ef838fce3",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da5bb0-cd6c-4c0a-a2af-b342ed341216",
   "metadata": {},
   "source": [
    "In this section, you will need to provide a clearly defined benchmark result or threshold for comparing across performances obtained by your solution. The reasoning behind the benchmark (in the case where it is not an established result) should be discussed. Questions to ask yourself when writing this section:\n",
    "- _Has some result or value been provided that acts as a benchmark for measuring performance?_\n",
    "- _Is it clear how this result or value was obtained (whether by data or by hypothesis)?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d944208-9a5f-405f-b1c6-0afbdeffa67f",
   "metadata": {},
   "source": [
    "## III. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf54ec0-ca71-4003-9932-b0c95723f27c",
   "metadata": {},
   "source": [
    "_(approx. 3-5 pages)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b19a4a-1a74-493d-8a2d-08c6adad4d77",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178eeeca-1bcb-4d61-b168-70288cd6f1db",
   "metadata": {},
   "source": [
    "In this section, all of your preprocessing steps will need to be clearly documented, if any were necessary. From the previous section, any of the abnormalities or characteristics that you identified about the dataset will be addressed and corrected here. Questions to ask yourself when writing this section:\n",
    "- _If the algorithms chosen require preprocessing steps like feature selection or feature transformations, have they been properly documented?_\n",
    "- _Based on the **Data Exploration** section, if there were abnormalities or characteristics that needed to be addressed, have they been properly corrected?_\n",
    "- _If no preprocessing is needed, has it been made clear why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e93396",
   "metadata": {},
   "source": [
    "Drop unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b94523-65d0-45a8-9d16-510e33400bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(axis=1, columns=['subject_id', 'pain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0754164",
   "metadata": {},
   "source": [
    "Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d846fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceased</th>\n",
       "      <th>gender</th>\n",
       "      <th>race_0</th>\n",
       "      <th>race_1</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>race_5</th>\n",
       "      <th>existing_doses</th>\n",
       "      <th>medicine_dispensations</th>\n",
       "      <th>...</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>acuity</th>\n",
       "      <th>arrival_transport_HELICOPTER</th>\n",
       "      <th>arrival_transport_OTHER</th>\n",
       "      <th>arrival_transport_UNKNOWN</th>\n",
       "      <th>arrival_transport_WALK IN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   deceased  gender  race_0  race_1  race_2  race_3  race_4  race_5  \\\n",
       "0         0       1       0       0       0       0       0       1   \n",
       "1         0       1       0       0       0       0       0       1   \n",
       "2         0       1       0       0       0       0       1       0   \n",
       "3         0       0       0       0       0       0       1       0   \n",
       "4         0       1       0       0       0       0       1       0   \n",
       "\n",
       "   existing_doses  medicine_dispensations  ...  heartrate  resprate  o2sat  \\\n",
       "0               0                       6  ...        NaN       NaN    NaN   \n",
       "1               1                      12  ...        NaN       NaN    NaN   \n",
       "2               4                       0  ...        NaN       NaN    NaN   \n",
       "3               1                       0  ...        NaN       NaN    NaN   \n",
       "4               0                       6  ...        NaN       NaN    NaN   \n",
       "\n",
       "   sbp  dbp  acuity  arrival_transport_HELICOPTER  arrival_transport_OTHER  \\\n",
       "0  NaN  NaN     NaN                             0                        0   \n",
       "1  NaN  NaN     NaN                             0                        0   \n",
       "2  NaN  NaN     NaN                             0                        0   \n",
       "3  NaN  NaN     NaN                             0                        0   \n",
       "4  NaN  NaN     NaN                             1                        0   \n",
       "\n",
       "   arrival_transport_UNKNOWN  arrival_transport_WALK IN  \n",
       "0                          0                          0  \n",
       "1                          0                          0  \n",
       "2                          0                          1  \n",
       "3                          0                          1  \n",
       "4                          0                          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df['arrival_transport'], prefix='arrival_transport', drop_first=True)\n",
    "df = df.join(dummies)\n",
    "df = df.drop('arrival_transport', axis=1)\n",
    "\n",
    "\n",
    "df = BinaryEncoder(cols=['race'], drop_invariant=True).fit_transform(df)\n",
    "df.head()\n",
    "# df = df.drop('race', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81de5ae",
   "metadata": {},
   "source": [
    "Scale these two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "469fabe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[ ['existing_doses', 'medicine_dispensations'] ] = scaler.fit_transform(\n",
    "    df[ ['existing_doses', 'medicine_dispensations'] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59389d33",
   "metadata": {},
   "source": [
    "Drop erroneous readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efc43a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sbp - drop values higher than 300 (even then, these are extreme)\n",
    "# dbp - drop values higher than 300 (even then, these are extreme)\n",
    "df = df[ (df['sbp'] <= 300) & (df['dbp'] <= 300) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca69203",
   "metadata": {},
   "source": [
    "Save processed file to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a957be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name='cleaned_data.csv'\n",
    "s3_prefix='data'\n",
    "object_name=os.path.join(s3_prefix, file_name)\n",
    "#Create csv from cleaned dataframe\n",
    "df.to_csv(file_name)\n",
    "#Save csv on s3 bucket\n",
    "try:\n",
    "    response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "except ClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa19b2a-87ef-48c7-9795-91e610a819ea",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d8fd9-6371-465a-9e36-ad87aa33e7b2",
   "metadata": {},
   "source": [
    "In this section, the process for which metrics, algorithms, and techniques that you implemented for the given data will need to be clearly documented. It should be abundantly clear how the implementation was carried out, and discussion should be made regarding any complications that occurred during this process. Questions to ask yourself when writing this section:\n",
    "- _Is it made clear how the algorithms and techniques were implemented with the given datasets or input data?_\n",
    "- _Were there any complications with the original metrics or techniques that required changing prior to acquiring a solution?_\n",
    "- _Was there any part of the coding process (e.g., writing complicated functions) that should be documented?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f94b930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(.001, .1),\n",
    "    \"batch_size\": CategoricalParameter([128, 256, 512, 1024]),\n",
    "    \"epochs\": CategoricalParameter([5, 10, 15]),\n",
    "}\n",
    "role = sagemaker.get_execution_role()\n",
    "objective_metric_name = \"Test Accuracy\"\n",
    "objective_type=\"Maximize\"\n",
    "metric_definitions=[{\"Name\": \"Test Accuracy\", \"Regex\": \"Testing Accuracy: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "634c5f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=role,\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    framework_version=\"1.12.0\",\n",
    "    py_version='py38',\n",
    "    source_dir='code/'\n",
    ")\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c73dd38-010e-4105-b9db-a8080cde4232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = os.path.join('s3://', bucket)\n",
    "os.environ['SM_CHANNEL_TRAINING']=os.path.join(base_path,'data')\n",
    "os.environ['SM_MODEL_DIR']=os.path.join(base_path,'model')\n",
    "os.environ['SM_OUTPUT_DATA_DIR']=os.path.join(base_path,'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39d8f00b-94d8-4d39-9391-33645ebcf7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-927441871693/model\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(base_path,'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d5030-6339-4129-9c58-19e09c219df5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"training\": base_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82536d4b",
   "metadata": {},
   "source": [
    "Describe the tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40cd5262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"1024\"</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>pytorch-training-230401-2207-002-1d6e063c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.914841</td>\n",
       "      <td>2023-04-01 22:08:17+00:00</td>\n",
       "      <td>2023-04-01 22:10:14+00:00</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"256\"</td>\n",
       "      <td>\"10\"</td>\n",
       "      <td>0.078536</td>\n",
       "      <td>pytorch-training-230401-2207-001-54c923be</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.914841</td>\n",
       "      <td>2023-04-01 22:08:18+00:00</td>\n",
       "      <td>2023-04-01 22:10:21+00:00</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  batch_size epochs  learning_rate                            TrainingJobName  \\\n",
       "0     \"1024\"    \"5\"       0.001828  pytorch-training-230401-2207-002-1d6e063c   \n",
       "1      \"256\"   \"10\"       0.078536  pytorch-training-230401-2207-001-54c923be   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0         Completed             0.914841 2023-04-01 22:08:17+00:00   \n",
       "1         Completed             0.914841 2023-04-01 22:08:18+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0 2023-04-01 22:10:14+00:00                       117.0  \n",
       "1 2023-04-01 22:10:21+00:00                       123.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = HyperparameterTuningJobAnalytics(\n",
    "  hyperparameter_tuning_job_name='pytorch-training-230401-2207')\n",
    "\n",
    "jobs = exp.dataframe()\n",
    "\n",
    "jobs.sort_values('FinalObjectiveValue', ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f7bda4c-4a8b-4563-be79-06a0d30137e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-04-01 22:10:24 Starting - Preparing the instances for training\n",
      "2023-04-01 22:10:24 Downloading - Downloading input data\n",
      "2023-04-01 22:10:24 Training - Training image download completed. Training in progress.\n",
      "2023-04-01 22:10:24 Uploading - Uploading generated training model\n",
      "2023-04-01 22:10:24 Completed - Resource released due to keep alive period expiry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"Test Accuracy\"',\n",
       " 'batch_size': '\"256\"',\n",
       " 'epochs': '\"10\"',\n",
       " 'learning_rate': '0.07853644622140321',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch-training-2023-04-01-22-07-06-922\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-927441871693/pytorch-training-2023-04-01-22-07-06-922/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the hyperparameters of the best trained model\n",
    "best_estimator = tuner.best_estimator()\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cccc98-9546-4195-bdc4-d6b6df8f1188",
   "metadata": {},
   "source": [
    "### Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abac048-8240-4661-ac85-273ddc165a99",
   "metadata": {},
   "source": [
    "In this section, you will need to discuss the process of improvement you made upon the algorithms and techniques you used in your implementation. For example, adjusting parameters for certain models to acquire improved solutions would fall under the refinement category. Your initial and final solutions should be reported, as well as any significant intermediate results as necessary. Questions to ask yourself when writing this section:\n",
    "- _Has an initial solution been found and clearly reported?_\n",
    "- _Is the process of improvement clearly documented, such as what techniques were used?_\n",
    "- _Are intermediate and final solutions clearly reported as the process is improved?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "234383e3-43ae-44fc-8e26-0e8624261c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_hyperparameters = {\n",
    "    'batch_size': '\"256\"',\n",
    "    'epochs': '\"10\"',\n",
    "    'learning_rate': '0.07853644622140321'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd9fc8d7-306c-41e2-813d-a9b7c1246f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deploy_estimator = PyTorch(\n",
    "    entry_point=\"train_and_deploy.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    framework_version=\"1.12.0\",\n",
    "    py_version='py38',\n",
    "    source_dir='code/',\n",
    "    hyperparameters=best_hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af7ba2d4-1ee7-4829-8925-88ec632e7a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-04-02-18-36-49-834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-02 18:37:04 Starting - Starting the training job...\n",
      "2023-04-02 18:37:20 Starting - Preparing the instances for training......\n",
      "2023-04-02 18:38:33 Downloading - Downloading input data\n",
      "2023-04-02 18:38:33 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:16,579 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:16,581 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:16,588 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:16,590 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:17,315 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting pytorch-tabular==1.0.1\u001b[0m\n",
      "\u001b[34mDownloading pytorch_tabular-1.0.1-py2.py3-none-any.whl (119 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.7/119.7 kB 18.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<=3.20.* in /opt/conda/lib/python3.8/site-packages (from pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (3.19.4)\u001b[0m\n",
      "\u001b[34mCollecting rich>=10.2.2\u001b[0m\n",
      "\u001b[34mDownloading rich-13.3.3-py3-none-any.whl (238 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 238.7/238.7 kB 42.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.8/site-packages (from pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.4.3)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard!=2.5.0,>=2.2.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 121.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.8.*\u001b[0m\n",
      "\u001b[34mDownloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 800.3/800.3 kB 87.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting omegaconf>=2.0.1\u001b[0m\n",
      "\u001b[34mDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 6.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting ipywidgets\u001b[0m\n",
      "\u001b[34mDownloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.3/138.3 kB 33.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting category-encoders==2.5.*\u001b[0m\n",
      "\u001b[34mDownloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.4/72.4 kB 25.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>3.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (3.5.3)\u001b[0m\n",
      "\u001b[34mCollecting pytorch-tabnet==4.0\u001b[0m\n",
      "\u001b[34mDownloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.8/41.8 kB 14.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.12.0+cpu)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.11.*\u001b[0m\n",
      "\u001b[34mDownloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 519.2/519.2 kB 86.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting einops==0.6.*\u001b[0m\n",
      "\u001b[34mDownloading einops-0.6.0-py3-none-any.whl (41 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.6/41.6 kB 13.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML<=5.4.1,>=5.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.22.2)\u001b[0m\n",
      "\u001b[34mCollecting statsmodels>=0.9.0\u001b[0m\n",
      "\u001b[34mDownloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 118.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting patsy>=0.5.1\u001b[0m\n",
      "\u001b[34mDownloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 kB 47.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from category-encoders==2.5.*->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.8.*->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2022.7.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX>=2.2\u001b[0m\n",
      "\u001b[34mDownloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 35.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.8.*->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
      "\u001b[34mCollecting lightning-utilities!=0.4.0,>=0.3.0\u001b[0m\n",
      "\u001b[34mDownloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.8.*->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (4.64.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.8.*->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>3.1->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (4.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>3.1->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>3.1->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>3.1->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>3.1->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (9.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>3.1->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (3.0.9)\u001b[0m\n",
      "\u001b[34mCollecting antlr4-python3-runtime==4.9.*\u001b[0m\n",
      "\u001b[34mDownloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 32.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.5->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2022.2.1)\u001b[0m\n",
      "\u001b[34mCollecting markdown-it-py<3.0.0,>=2.2.0\u001b[0m\n",
      "\u001b[34mDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.5/84.5 kB 26.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from rich>=10.2.2->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.0.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.0.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 81.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.48.2\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 124.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.8.0,>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 133.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<1.1,>=0.5\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.4.3-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 30.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.17.1-py2.py3-none-any.whl (178 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.1/178.1 kB 50.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (65.3.0)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 28.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting protobuf<=3.20.*\u001b[0m\n",
      "\u001b[34mDownloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 101.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2.2.2)\u001b[0m\n",
      "\u001b[34mCollecting widgetsnbextension~=4.0.7\u001b[0m\n",
      "\u001b[34mDownloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 109.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting ipykernel>=4.5.1\u001b[0m\n",
      "\u001b[34mDownloading ipykernel-6.22.0-py3-none-any.whl (149 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.0/150.0 kB 35.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (8.1.0)\u001b[0m\n",
      "\n",
      "2023-04-02 18:39:08 Training - Training image download completed. Training in progress.\u001b[34mCollecting jupyterlab-widgets~=3.0.7\u001b[0m\n",
      "\u001b[34mDownloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 198.2/198.2 kB 48.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (5.3.0)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 91.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 40.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-core!=5.0.*,>=4.12\u001b[0m\n",
      "\u001b[34mDownloading jupyter_core-5.3.0-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.2/93.2 kB 27.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.1.6)\u001b[0m\n",
      "\u001b[34mCollecting debugpy>=1.6.5\u001b[0m\n",
      "\u001b[34mDownloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 121.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting comm>=0.1.1\u001b[0m\n",
      "\u001b[34mDownloading comm-0.1.3-py3-none-any.whl (6.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting traitlets>=4.3.1\u001b[0m\n",
      "\u001b[34mDownloading traitlets-5.9.0-py3-none-any.whl (117 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.4/117.4 kB 24.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting jupyter-client>=6.1.12\u001b[0m\n",
      "\u001b[34mDownloading jupyter_client-8.1.0-py3-none-any.whl (102 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.9/102.9 kB 35.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting nest-asyncio\u001b[0m\n",
      "\u001b[34mDownloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (5.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (6.2)\u001b[0m\n",
      "\u001b[34mCollecting pyzmq>=20\u001b[0m\n",
      "\u001b[34mDownloading pyzmq-25.0.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 102.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (3.0.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (4.12.0)\u001b[0m\n",
      "\u001b[34mCollecting mdurl~=0.1\u001b[0m\n",
      "\u001b[34mDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.26.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.8.3)\u001b[0m\n",
      "\u001b[34mCollecting platformdirs>=2.5\u001b[0m\n",
      "\u001b[34mDownloading platformdirs-3.2.0-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.2.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 35.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 262.1/262.1 kB 48.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 21.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 32.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (21.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (2.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (0.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular==1.0.1->-r requirements.txt (line 1)) (1.0.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: antlr4-python3-runtime\u001b[0m\n",
      "\u001b[34mBuilding wheel for antlr4-python3-runtime (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d809456058b5ff493741f08be0ec508cc18dc527dfe1feb67b5c05474a478092\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\u001b[0m\n",
      "\u001b[34mSuccessfully built antlr4-python3-runtime\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tensorboard-plugin-wit, antlr4-python3-runtime, widgetsnbextension, traitlets, tensorboard-data-server, pyzmq, pyasn1-modules, protobuf, platformdirs, patsy, omegaconf, oauthlib, nest-asyncio, multidict, mdurl, jupyterlab-widgets, grpcio, frozenlist, einops, debugpy, cachetools, async-timeout, absl-py, yarl, torchmetrics, tensorboardX, requests-oauthlib, markdown-it-py, markdown, lightning-utilities, jupyter-core, google-auth, comm, aiosignal, statsmodels, rich, pytorch-tabnet, jupyter-client, google-auth-oauthlib, aiohttp, tensorboard, ipykernel, category-encoders, pytorch-lightning, ipywidgets, pytorch-tabular\u001b[0m\n",
      "\u001b[34mAttempting uninstall: traitlets\u001b[0m\n",
      "\u001b[34mFound existing installation: traitlets 5.3.0\u001b[0m\n",
      "\u001b[34mUninstalling traitlets-5.3.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled traitlets-5.3.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: protobuf\u001b[0m\n",
      "\u001b[34mFound existing installation: protobuf 3.19.4\u001b[0m\n",
      "\u001b[34mUninstalling protobuf-3.19.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled protobuf-3.19.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 cachetools-5.3.0 category-encoders-2.5.1.post0 comm-0.1.3 debugpy-1.6.6 einops-0.6.0 frozenlist-1.3.3 google-auth-2.17.1 google-auth-oauthlib-1.0.0 grpcio-1.53.0 ipykernel-6.22.0 ipywidgets-8.0.6 jupyter-client-8.1.0 jupyter-core-5.3.0 jupyterlab-widgets-3.0.7 lightning-utilities-0.8.0 markdown-3.4.3 markdown-it-py-2.2.0 mdurl-0.1.2 multidict-6.0.4 nest-asyncio-1.5.6 oauthlib-3.2.2 omegaconf-2.3.0 patsy-0.5.3 platformdirs-3.2.0 protobuf-3.19.6 pyasn1-modules-0.2.8 pytorch-lightning-1.8.6 pytorch-tabnet-4.0 pytorch-tabular-1.0.1 pyzmq-25.0.2 requests-oauthlib-1.3.1 rich-13.3.3 statsmodels-0.13.5 tensorboard-2.12.1 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorboardX-2.6 torchmetrics-0.11.4 traitlets-5.9.0 widgetsnbextension-4.0.7 yarl-1.8.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:31,730 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:31,730 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:31,733 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:31,743 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:31,755 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:31,763 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": \"\\\"256\\\"\",\n",
      "        \"epochs\": \"\\\"10\\\"\",\n",
      "        \"learning_rate\": \"0.07853644622140321\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2023-04-02-18-36-49-834\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-927441871693/pytorch-training-2023-04-02-18-36-49-834/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_and_deploy\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_and_deploy.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":\"\\\"256\\\"\",\"epochs\":\"\\\"10\\\"\",\"learning_rate\":\"0.07853644622140321\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_and_deploy.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_and_deploy\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-927441871693/pytorch-training-2023-04-02-18-36-49-834/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":\"\\\"256\\\"\",\"epochs\":\"\\\"10\\\"\",\"learning_rate\":\"0.07853644622140321\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2023-04-02-18-36-49-834\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-927441871693/pytorch-training-2023-04-02-18-36-49-834/source/sourcedir.tar.gz\",\"module_name\":\"train_and_deploy\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_and_deploy.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"\\\"256\\\"\",\"--epochs\",\"\\\"10\\\"\",\"--learning_rate\",\"0.07853644622140321\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=\"256\"\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=\"10\"\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.07853644622140321\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train_and_deploy.py --batch_size \"256\" --epochs \"10\" --learning_rate 0.07853644622140321\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_tabular/models/mixture_density/mdn.py:25: UserWarning: Wandb not installed. WandbLogger will not work.\n",
      "  warnings.warn(\"Wandb not installed. WandbLogger will not work.\")\u001b[0m\n",
      "\u001b[34mNamespace(batch_size=256, data='/opt/ml/input/data/training', epochs=10, learning_rate=0.07853644622140321, model_dir='/opt/ml/model', output_dir='/opt/ml/output/data')\u001b[0m\n",
      "\u001b[34mHyperparameters are LR: 0.07853644622140321, Batch Size: 256\u001b[0m\n",
      "\u001b[34mData Paths: /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:34,897 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\u001b[0m\n",
      "\u001b[34mStarting Model Training\u001b[0m\n",
      "\u001b[34mGlobal seed set to 42\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:34,914 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:34,926 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for classification task\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:35,587 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: CategoryEmbeddingModel\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_tabular/models/base_model.py:126: UserWarning: Wandb is not installed. Please install wandb to log logits. You can install wandb using pip install wandb or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:35,622 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\u001b[0m\n",
      "\u001b[34mGPU available: False, used: False\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34mHPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:35,687 - {pytorch_tabular.tabular_model:558} - INFO - Auto LR Find Started\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /opt/ml/code/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m[2023-04-02 18:39:35.737 algo-1:74 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2023-04-02 18:39:35.892 algo-1:74 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-04-02 18:39:35.893 algo-1:74 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-04-02 18:39:35.893 algo-1:74 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-04-02 18:39:35.894 algo-1:74 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-04-02 18:39:35.894 algo-1:74 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mFinding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:   7%|▋         | 7/100 [00:00<00:01, 63.90it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  14%|█▍        | 14/100 [00:00<00:01, 65.33it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  21%|██        | 21/100 [00:00<00:01, 66.20it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  28%|██▊       | 28/100 [00:00<00:01, 66.35it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  35%|███▌      | 35/100 [00:00<00:01, 64.21it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  42%|████▏     | 42/100 [00:00<00:00, 64.24it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  49%|████▉     | 49/100 [00:00<00:00, 64.85it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  56%|█████▌    | 56/100 [00:00<00:00, 65.62it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  63%|██████▎   | 63/100 [00:00<00:00, 65.98it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  70%|███████   | 70/100 [00:01<00:00, 65.88it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  77%|███████▋  | 77/100 [00:01<00:00, 65.53it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  84%|████████▍ | 84/100 [00:01<00:00, 66.02it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  91%|█████████ | 91/100 [00:01<00:00, 66.64it/s]\u001b[0m\n",
      "\u001b[34mFinding best initial lr:  98%|█████████▊| 98/100 [00:01<00:00, 65.55it/s]\u001b[0m\n",
      "\u001b[34m`Trainer.fit` stopped: `max_steps=100` reached.\u001b[0m\n",
      "\u001b[34mFinding best initial lr: 100%|██████████| 100/100 [00:01<00:00, 65.37it/s]\u001b[0m\n",
      "\u001b[34mFailed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\u001b[0m\n",
      "\u001b[34mRestoring states from the checkpoint path at /opt/ml/code/.lr_find_37b0d9b2-397c-4f24-a91e-e9e545a522ab.ckpt\u001b[0m\n",
      "\u001b[34mRestored all states from the checkpoint file at /opt/ml/code/.lr_find_37b0d9b2-397c-4f24-a91e-e9e545a522ab.ckpt\u001b[0m\n",
      "\u001b[34mFailed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:38,122 - {pytorch_tabular.tabular_model:560} - INFO - Suggested LR: None. For plot and detailed analysis, use `find_learning_rate` method.\u001b[0m\n",
      "\u001b[34mINFO:pytorch_tabular.tabular_model:Suggested LR: None. For plot and detailed analysis, use `find_learning_rate` method.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:38,123 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\u001b[0m\n",
      "\u001b[34mINFO:pytorch_tabular.tabular_model:Training Started\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /opt/ml/code/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\u001b[0m\n",
      "\u001b[34m┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\u001b[0m\n",
      "\u001b[34m┃   ┃ Name             ┃ Type                      ┃ Params ┃\u001b[0m\n",
      "\u001b[34m┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\u001b[0m\n",
      "\u001b[34m│ 0 │ _backbone        │ CategoryEmbeddingBackbone │  809 K │\u001b[0m\n",
      "\u001b[34m│ 1 │ _embedding_layer │ Embedding1dLayer          │     42 │\u001b[0m\n",
      "\u001b[34m│ 2 │ head             │ LinearHead                │  1.0 K │\u001b[0m\n",
      "\u001b[34m│ 3 │ loss             │ CrossEntropyLoss          │      0 │\u001b[0m\n",
      "\u001b[34m└───┴──────────────────┴───────────────────────────┴────────┘\u001b[0m\n",
      "\u001b[34mTrainable params: 811 K                                                         \u001b[0m\n",
      "\u001b[34mNon-trainable params: 0                                                         \u001b[0m\n",
      "\u001b[34mTotal params: 811 K                                                             \u001b[0m\n",
      "\u001b[34mTotal estimated model params size (MB): 3\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\u001b[0m\n",
      "\u001b[34mEpoch 0/9  ━━━━━━━━━━━━━━━━ 755/755 0:00:11 •        67.21it/s loss: nan        \n",
      "                                    0:00:00                    train_loss: nan  \n",
      "                                                               valid_loss: nan  \n",
      "                                                               valid_accuracy:  \n",
      "                                                               0.915            \n",
      "                                                               train_accuracy:  \n",
      "                                                               0.915\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:49,426 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\u001b[0m\n",
      "\u001b[34mINFO:pytorch_tabular.tabular_model:Training the model completed\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:49,426 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\u001b[0m\n",
      "\u001b[34mINFO:pytorch_tabular.tabular_model:Loading the best model\u001b[0m\n",
      "\u001b[34mTesting Model\u001b[0m\n",
      "\u001b[34mINFO:__main__:Testing Model\u001b[0m\n",
      "\u001b[34mGenerating Predictions... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00\u001b[0m\n",
      "\u001b[34mTesting Accuracy: 0.9148407148407148\u001b[0m\n",
      "\u001b[34mSaving Model\u001b[0m\n",
      "\u001b[34mINFO:__main__:Testing Accuracy: 0.9148407148407148\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving Model\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:51,001 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:51,001 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-04-02 18:39:51,001 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-04-02 18:39:54 Uploading - Uploading generated training model\n",
      "2023-04-02 18:40:10 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n"
     ]
    }
   ],
   "source": [
    "deploy_estimator.fit({\"training\": base_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2cd7ec1-7aa3-4f79-8b20-a89ff2338e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: pytorch-training-2023-04-01-23-23-22-022\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-training-2023-04-01-23-23-22-022\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-2023-04-01-23-23-22-022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = deploy_estimator.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdca50f6-8206-454f-854c-c2ea9c2c023f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2023-04-01-23-23-22-022 in account 927441871693 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8983/3052845101.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Randomly select a sample (row) from the entire dataset, and make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2023-04-01-23-23-22-022 in account 927441871693 for more information."
     ]
    }
   ],
   "source": [
    "#Randomly select a sample (row) from the entire dataset, and make a prediction\n",
    "test_sample = df.sample()\n",
    "response = predictor.predict(test_sample)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60b738-5162-401b-a1ce-8d8b8945a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The correct label was: {test_sample[deceased]}. The predicted label was:{response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e206471-319b-4ecb-8a2c-58e46449596a",
   "metadata": {},
   "source": [
    "## IV. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e1d99-4d99-4f6e-906b-c7f694ceede6",
   "metadata": {},
   "source": [
    "_(approx. 2-3 pages)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31bfc4-57ef-495a-9460-1259cae2cbf8",
   "metadata": {},
   "source": [
    "### Model Evaluation and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25361bb4-9742-485c-9f55-2281f6663fe4",
   "metadata": {},
   "source": [
    "In this section, the final model and any supporting qualities should be evaluated in detail. It should be clear how the final model was derived and why this model was chosen. In addition, some type of analysis should be used to validate the robustness of this model and its solution, such as manipulating the input data or environment to see how the model’s solution is affected (this is called sensitivity analysis). Questions to ask yourself when writing this section:\n",
    "- _Is the final model reasonable and aligning with solution expectations? Are the final parameters of the model appropriate?_\n",
    "- _Has the final model been tested with various inputs to evaluate whether the model generalizes well to unseen data?_\n",
    "- _Is the model robust enough for the problem? Do small perturbations (changes) in training data or the input space greatly affect the results?_\n",
    "- _Can results found from the model be trusted?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58da0c-71bf-4536-87f8-360986ee6138",
   "metadata": {},
   "source": [
    "### Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f8f8b-2aac-44c4-852a-4b6793133522",
   "metadata": {},
   "source": [
    "In this section, your model’s final solution and its results should be compared to the benchmark you established earlier in the project using some type of statistical analysis. You should also justify whether these results and the solution are significant enough to have solved the problem posed in the project. Questions to ask yourself when writing this section:\n",
    "- _Are the final results found stronger than the benchmark result reported earlier?_\n",
    "- _Have you thoroughly analyzed and discussed the final solution?_\n",
    "- _Is the final solution significant enough to have solved the problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d857b-c98f-4670-87f8-225e547c0020",
   "metadata": {},
   "source": [
    "## V. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b56aad-8da4-422d-985e-535d3018ab95",
   "metadata": {},
   "source": [
    "_(approx. 1-2 pages)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db7fab-9bae-4987-bef0-4517da2e0660",
   "metadata": {},
   "source": [
    "### Free-Form Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c3fad-9f20-4a01-8213-3745d9cf8e92",
   "metadata": {},
   "source": [
    "In this section, you will need to provide some form of visualization that emphasizes an important quality about the project. It is much more free-form, but should reasonably support a significant result or characteristic about the problem that you want to discuss. Questions to ask yourself when writing this section:\n",
    "- _Have you visualized a relevant or important quality about the problem, dataset, input data, or results?_\n",
    "- _Is the visualization thoroughly analyzed and discussed?_\n",
    "- _If a plot is provided, are the axes, title, and datum clearly defined?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54477d-e695-46a8-bc87-7caf04cae91e",
   "metadata": {},
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e86c7-46d6-4097-a7f5-5a9487750d0f",
   "metadata": {},
   "source": [
    "In this section, you will summarize the entire end-to-end problem solution and discuss one or two particular aspects of the project you found interesting or difficult. You are expected to reflect on the project as a whole to show that you have a firm understanding of the entire process employed in your work. Questions to ask yourself when writing this section:\n",
    "- _Have you thoroughly summarized the entire process you used for this project?_\n",
    "- _Were there any interesting aspects of the project?_\n",
    "- _Were there any difficult aspects of the project?_\n",
    "- _Does the final model and solution fit your expectations for the problem, and should it be used in a general setting to solve these types of problems?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7db32-cbe7-4110-a9d2-e249fd1b95d4",
   "metadata": {},
   "source": [
    "### Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541295a5-2dbc-43d3-98c5-7b19b8f3b86f",
   "metadata": {},
   "source": [
    "In this section, you will need to provide discussion as to how one aspect of the implementation you designed could be improved. As an example, consider ways your implementation can be made more general, and what would need to be modified. You do not need to make this improvement, but the potential solutions resulting from these changes are considered and compared/contrasted to your current solution. Questions to ask yourself when writing this section:\n",
    "- _Are there further improvements that could be made on the algorithms or techniques you used in this project?_\n",
    "- _Were there algorithms or techniques you researched that you did not know how to implement, but would consider using if you knew how?_\n",
    "- _If you used your final solution as the new benchmark, do you think an even better solution exists?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1e0d1-5b5e-4585-a5e7-fe42376a1203",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205a9a2-6cd4-4f66-bdcb-b997a0d5435d",
   "metadata": {},
   "source": [
    "**Before submitting, ask yourself. . .**\n",
    "\n",
    "- Does the project report you’ve written follow a well-organized structure similar to that of the project template?\n",
    "- Is each section (particularly **Analysis** and **Methodology**) written in a clear, concise and specific fashion? Are there any ambiguous terms or phrases that need clarification?\n",
    "- Would the intended audience of your project be able to understand your analysis, methods, and results?\n",
    "- Have you properly proof-read your project report to assure there are minimal grammatical and spelling mistakes?\n",
    "- Are all the resources used for this project correctly cited and referenced?\n",
    "- Is the code that implements your solution easily readable and properly commented?\n",
    "- Does the code execute without error and produce results similar to those reported?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
